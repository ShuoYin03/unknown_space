<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nlp on UNKNOWN SPACE</title>
    <link>https://shuoyin03.github.io/tags/nlp/</link>
    <description>Recent content in nlp on UNKNOWN SPACE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 20 Jan 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://shuoyin03.github.io/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Natural Language Processing - Information Extraction</title>
      <link>https://shuoyin03.github.io/2024/01/18/nlp-information-extraction/</link>
      <pubDate>Sat, 20 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>https://shuoyin03.github.io/2024/01/18/nlp-information-extraction/</guid>
      <description>What is information Extraction? Entities Named Entity Recognition (NER) Many types of named entities
Dictionary-Based: Look-Up Approach In dictionary-based approach, system will only recognize those words appears in the dictionary, it is simple and fast. However, the more common things are, it can&amp;rsquo;t enumerate all names within the texts and can&amp;rsquo;t resolve ambiguity. Moreover, the maintenance of lists is also a problem.
Rule-Based Approach The rule-based approach uses some context clues to identify entities.</description>
    </item>
    
    <item>
      <title>Natural Language Processing - Speech Processing</title>
      <link>https://shuoyin03.github.io/2024/01/18/nlp-speech-processing/</link>
      <pubDate>Thu, 18 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>https://shuoyin03.github.io/2024/01/18/nlp-speech-processing/</guid>
      <description>Why is Speech Recognition so Hard We could analyze this problem in two perspectives: From a linguistic perspective, there are many questions to be asked - How many speakers are there? Are they speaking continuously or isolated? Are there any environment noise? How are the channel conditions? Speaker tuned for a particular speaker, or speaker independent? Every question could act on a great impact on the performance. And from a machine learning perspective, if we define speech recognition as a classification problem, it contains very high dimensional output space.</description>
    </item>
    
    <item>
      <title>Natural Language Processing - Deep Learning I</title>
      <link>https://shuoyin03.github.io/2024/01/16/nlp-deep-learning1/</link>
      <pubDate>Tue, 16 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>https://shuoyin03.github.io/2024/01/16/nlp-deep-learning1/</guid>
      <description>Basic Neural Network Structure Single neuron, the most basic components of neural networks, consist of multiple inputs $[x_1, x_2, &amp;hellip;, x_d]$ and an output $y$. The above picture demonstrated, each input $x$ is multiply by a weight $w$, their sum is added with a bias and then activated by a activation function. The training process, is to find the best y value from updating the weight in each training epoch.</description>
    </item>
    
    <item>
      <title>Natural Language Processing - POS Tagging</title>
      <link>https://shuoyin03.github.io/2024/01/04/nlp-pos-tagging/</link>
      <pubDate>Thu, 04 Jan 2024 00:00:00 +0000</pubDate>
      
      <guid>https://shuoyin03.github.io/2024/01/04/nlp-pos-tagging/</guid>
      <description>In this article we will have a look at POS tagging, what is it? How do we apply it to NLP tasks?
POS POS - &amp;ldquo;Part of Speech&amp;rdquo;, represent a linguistic category, defined the syntactic or morphological behavior of words. “Traditional” categories contains 8 tags, they are:
verb None Adverb Adjective Interjection Pronoun Preposition Conjunction The previous 5 categories are called the open word classes, which means that these types always have a large amount of vocabularies and new words could be added into these categories.</description>
    </item>
    
    <item>
      <title>Natural Language Processing - Text Representation</title>
      <link>https://shuoyin03.github.io/2023/12/21/nlp-text-representation/</link>
      <pubDate>Thu, 21 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://shuoyin03.github.io/2023/12/21/nlp-text-representation/</guid>
      <description>In this article we will have a look at how to represent texts in data forms for further nlp processes.
BoW Representation BoW - &amp;ldquo;Bag of words&amp;rdquo;, should be the simplest model, which reduce each document into a bag of words. BoW is an efficient method which nowadays lots of NLP system is using it. However, there are some question we should think of while using it, such as:</description>
    </item>
    
    <item>
      <title>Natural Language Processing - Text Pre-processing</title>
      <link>https://shuoyin03.github.io/2023/12/19/nlp-text-preprocessing/</link>
      <pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://shuoyin03.github.io/2023/12/19/nlp-text-preprocessing/</guid>
      <description>In this article, we are going to look at general steps of text pre-processing. Tokenization Word-Based Tokenization Tokenization is the first step of text pre-processing, it is to split a bunch of text into a list of tokens. As an example, we could split “a cat on a pat” to [“a”, “cat”, “on”,</description>
    </item>
    
  </channel>
</rss>
