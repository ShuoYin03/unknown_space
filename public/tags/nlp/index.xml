<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>nlp on UNKNOWN SPACE</title>
    <link>https://shuoyin03.github.io/tags/nlp/</link>
    <description>Recent content in nlp on UNKNOWN SPACE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Dec 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://shuoyin03.github.io/tags/nlp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Natural Language Processing - Text Representation</title>
      <link>https://shuoyin03.github.io/2023/12/21/nlp-text-representation/</link>
      <pubDate>Thu, 21 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://shuoyin03.github.io/2023/12/21/nlp-text-representation/</guid>
      <description>In this article we will have a look at how to represent texts in data forms for further nlp processes.
BoW Representation BoW - &amp;ldquo;Bag of words&amp;rdquo;, should be the simplest model, which reduce each document into a bag of words. BoW is an efficient method which nowadays lots of NLP system is using it. However, there are some question we should think of while using it, such as:</description>
    </item>
    
    <item>
      <title>Natural Language Processing - Text Pre-processing</title>
      <link>https://shuoyin03.github.io/2023/12/19/nlp-text-preprocessing/</link>
      <pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://shuoyin03.github.io/2023/12/19/nlp-text-preprocessing/</guid>
      <description>In this article, we are going to look at general steps of text pre-processing. Tokenization Word-Based Tokenization Tokenization is the first step of text pre-processing, it is to split a bunch of text into a list of tokens. As an example, we could split “a cat on a pat” to [“a”, “cat”, “on”,</description>
    </item>
    
  </channel>
</rss>
